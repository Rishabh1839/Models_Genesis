{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1267593,"sourceType":"datasetVersion","datasetId":723383}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rishabhsingh18/models-genesis-experiment?scriptVersionId=188204650\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nimport nibabel as nib\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2024-07-06T20:37:18.534865Z","iopub.execute_input":"2024-07-06T20:37:18.536035Z","iopub.status.idle":"2024-07-06T20:37:18.543188Z","shell.execute_reply.started":"2024-07-06T20:37:18.535981Z","shell.execute_reply":"2024-07-06T20:37:18.54189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data collection and pre processing, we use the BraTS dataset which is about Brain tumor","metadata":{}},{"cell_type":"code","source":"# Helper Functions\ndef load_nifti_image(file_path):\n    img = nib.load(file_path)\n    img_data = img.get_fdata()\n    return img_data\n\n\ndef preprocess_image(img):\n    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n    return img\n\n\ndef create_inpainting_task(inputs):\n    # Mask random parts of the input image\n    mask = torch.rand(inputs.shape) > 0.85\n    masked_inputs = inputs.clone()\n    masked_inputs[mask] = 0\n    return masked_inputs, inputs\n\n\ndef dice_coefficient(pred, target, smooth=1e-5):\n    intersection = (pred * target).sum()\n    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T20:37:18.545486Z","iopub.execute_input":"2024-07-06T20:37:18.545942Z","iopub.status.idle":"2024-07-06T20:37:18.564131Z","shell.execute_reply.started":"2024-07-06T20:37:18.545901Z","shell.execute_reply":"2024-07-06T20:37:18.562565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Model Design and Training - here we define a 3D U-Net model and train it using self supervised tasks like image inpainting.","metadata":{}},{"cell_type":"code","source":"# Define the Dataset Classes\nclass MedicalDataset(Dataset):\n    def __init__(self, images):\n        self.images = images\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        return img\n\n\nclass SegmentationDataset(Dataset):\n    def __init__(self, images, labels):\n        self.images = images\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        lbl = self.labels[idx]\n        return img, lbl","metadata":{"execution":{"iopub.status.busy":"2024-07-06T20:37:18.566323Z","iopub.execute_input":"2024-07-06T20:37:18.566789Z","iopub.status.idle":"2024-07-06T20:37:18.57973Z","shell.execute_reply.started":"2024-07-06T20:37:18.566727Z","shell.execute_reply":"2024-07-06T20:37:18.578338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the 3D U-Net Model\nclass UNet3D(nn.Module):\n    def __init__(self):\n        super(UNet3D, self).__init__()\n        # Encoder\n        self.enc1 = nn.Sequential(nn.Conv3d(1, 32, 3, padding=1), nn.ReLU(), nn.Conv3d(32, 32, 3, padding=1), nn.ReLU())\n        self.enc2 = nn.Sequential(nn.MaxPool3d(2), nn.Conv3d(32, 64, 3, padding=1), nn.ReLU(), nn.Conv3d(64, 64, 3, padding=1), nn.ReLU())\n        self.enc3 = nn.Sequential(nn.MaxPool3d(2), nn.Conv3d(64, 128, 3, padding=1), nn.ReLU(), nn.Conv3d(128, 128, 3, padding=1), nn.ReLU())\n        \n        # Decoder\n        self.dec3 = nn.Sequential(nn.ConvTranspose3d(128, 64, 2, stride=2), nn.Conv3d(64, 64, 3, padding=1), nn.ReLU(), nn.Conv3d(64, 64, 3, padding=1), nn.ReLU())\n        self.dec2 = nn.Sequential(nn.ConvTranspose3d(64, 32, 2, stride=2), nn.Conv3d(32, 32, 3, padding=1), nn.ReLU(), nn.Conv3d(32, 32, 3, padding=1), nn.ReLU())\n        self.dec1 = nn.Conv3d(32, 1, 1)\n\n    def forward(self, x):\n        # Encoder\n        e1 = self.enc1(x)\n        e2 = self.enc2(e1)\n        e3 = self.enc3(e2)\n        \n        # Decoder\n        d3 = self.dec3(e3)\n        d2 = self.dec2(d3 + e2)\n        d1 = self.dec1(d2 + e1)\n        \n        return d1","metadata":{"execution":{"iopub.status.busy":"2024-07-06T20:37:18.581146Z","iopub.execute_input":"2024-07-06T20:37:18.581534Z","iopub.status.idle":"2024-07-06T20:37:18.597046Z","shell.execute_reply.started":"2024-07-06T20:37:18.581493Z","shell.execute_reply":"2024-07-06T20:37:18.595806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Main Experiment\ndef main():\n    # Load and preprocess the dataset\n    data_dir = '/kaggle/input/brats2020-training-data/BraTS20 Training Metadata.csv'\n    image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.nii')]\n    images = [preprocess_image(load_nifti_image(f)) for f in image_files]\n    \n    # Split the dataset into training and validation sets\n    train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n    \n    # Define the model, loss function, and optimizer\n    model = UNet3D().cuda()\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Data loaders for self-supervised training\n    train_dataset = MedicalDataset(train_images)\n    val_dataset = MedicalDataset(val_images)\n    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=4)\n    \n    # Self-supervised training loop\n    for epoch in range(100):\n        model.train()\n        running_loss = 0.0\n        for data in train_loader:\n            inputs = data.unsqueeze(1).float().cuda()\n            masked_inputs, targets = create_inpainting_task(inputs)\n            optimizer.zero_grad()\n            outputs = model(masked_inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n    \n    # Load segmentation labels and preprocess\n    segmentation_labels = [preprocess_image(load_nifti_image(f.replace('image', 'label'))) for f in image_files]\n    labels = [preprocess_image(lbl) for lbl in segmentation_labels]\n    train_labels, val_labels = train_test_split(labels, test_size=0.2, random_state=42)\n    \n    # Update the dataset class to include labels\n    train_dataset = SegmentationDataset(train_images, train_labels)\n    val_dataset = SegmentationDataset(val_images, val_labels)\n    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=4)\n    \n    # Redefine the loss function for segmentation\n    criterion = nn.CrossEntropyLoss()\n    \n    # Fine-tuning loop\n    for epoch in range(50):\n        model.train()\n        running_loss = 0.0\n        for data in train_loader:\n            inputs, labels = data\n            inputs, labels = inputs.unsqueeze(1).float().cuda(), labels.unsqueeze(1).float().cuda()\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n        \n        # Validate the model\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for data in val_loader:\n                inputs, labels = data\n                inputs, labels = inputs.unsqueeze(1).float().cuda(), labels.unsqueeze(1).float().cuda()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n        \n        print(f'Validation Loss: {val_loss/len(val_loader)}')\n    \n    # Evaluation on the validation set\n    model.eval()\n    dice_scores = []\n    with torch.no_grad():\n        for data in val_loader:\n            inputs, labels = data\n            inputs, labels = inputs.unsqueeze(1).float().cuda(), labels.unsqueeze(1).float().cuda()\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1)\n            dice = dice_coefficient(preds.cpu().numpy(), labels.cpu().numpy())\n    print(f'Mean Dice Coefficient: {np.mean(dice_scores)}')\n\n\nif __name__ == '__main__':\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T20:37:18.599586Z","iopub.execute_input":"2024-07-06T20:37:18.599982Z","iopub.status.idle":"2024-07-06T20:37:18.765497Z","shell.execute_reply.started":"2024-07-06T20:37:18.599952Z","shell.execute_reply":"2024-07-06T20:37:18.763848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References :\n\n\nSure, here are the references for downloading the BraTS dataset:\n\n### 1. Medical Segmentation Decathlon\n- **Website**: [Medical Segmentation Decathlon](http://medicaldecathlon.com/)\n- **Dataset**: The BraTS dataset is available as part of the Medical Segmentation Decathlon challenge, which provides multiple medical imaging datasets for various tasks.\n\n### 2. BraTS Challenge\n- **Website**: [BraTS Challenge](https://www.med.upenn.edu/cbica/brats2020/data.html)\n- **Dataset**: The BraTS Challenge focuses on the segmentation of brain tumors and provides datasets for training and validation, along with detailed instructions on how to download and use the data.\n\n### 3. Kaggle\n- **Website**: [Kaggle BraTS Dataset](https://www.kaggle.com/datasets/awsaf49/brats20-dataset-training-validation)\n- **Dataset**: Kaggle hosts the BraTS dataset, making it easy to download and integrate into your machine learning workflows. You can use the Kaggle API to download the dataset directly.\n\n### Additional References\nFor more detailed instructions on setting up the Kaggle API and downloading datasets, refer to the official Kaggle documentation:\n- **Kaggle API Documentation**: [Kaggle API](https://www.kaggle.com/docs/api)\n\n### Steps for Downloading and Using the Dataset\n\n#### 1. Medical Segmentation Decathlon\nTo download the dataset from the Medical Segmentation Decathlon:\n1. Visit [Medical Segmentation Decathlon](http://medicaldecathlon.com/).\n2. Find the BraTS dataset listed under the available datasets.\n3. Follow the provided instructions to download the dataset.\n\n#### 2. BraTS Challenge\nTo download the dataset from the BraTS Challenge:\n1. Visit [BraTS Challenge](https://www.med.upenn.edu/cbica/brats2020/data.html).\n2. Register for the challenge if required.\n3. Download the training and validation datasets from the provided links.\n\n#### 3. Kaggle\nTo download the dataset from Kaggle:\n1. Ensure you have the Kaggle API installed (`pip install kaggle`).\n2. Set up your Kaggle API key by following the [instructions](https://www.kaggle.com/docs/api).\n3. Use the following commands to download and extract the dataset:\n\n```bash\nkaggle datasets download awsaf49/brats20-dataset-training-validation\nunzip brats20-dataset-training-validation.zip -d path_to_extract\n```\n\n### Example Script for Downloading from Kaggle\n\nHereâ€™s a script to download the dataset using the Kaggle API:\n\n```bash\n# Install Kaggle API\npip install kaggle\n\n# Download the dataset\nkaggle datasets download awsaf49/brats20-dataset-training-validation\n\n# Extract the dataset\nunzip brats20-dataset-training-validation.zip -d path_to_extract\n```\n\n### Summary\nThese references and steps should help you download and set up the BraTS dataset for your experiment. If you need more information or assistance, feel free to ask!","metadata":{}}]}